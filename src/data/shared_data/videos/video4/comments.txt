Final a guy who talk about real ai implantation in a technical way without all clickbait doomsday AI nonsense.<br>great job, keep it that way !
Question here some from relatively experienced backend software engineer. I use openai‚Äôs ai assistant api as the core ai in the webapplication im building. My question is doesnt the ai assistant api basically perform the same purpose. Does implement langchain / langgraph replace the the need for the openai ai assistant. Like whats the difference? Is same in principle but the pydanticai langchain langgraph allow for more dynamic flexibility and performance?
is PydanticAI  yours?
Have you uploaded this tutorial code on your repo?
Yep it&#39;s in the description!
‚ÄúI‚Äôm spending a lot of time on the why, because it‚Äôs just as important as the how‚Äù<br>This is what is missing in most of the stuff I‚Äôve been watching about this so far!
I appreciate you calling that out! :D
Could you do a video on smolagents? I have had a little play and I think their approach is intriguing instead of the restrictive JSON response approach
I actually covered Smolagents in this video!<br><br><a href="https://www.youtube.com/watch?v=uWDocIoiaXE">https://www.youtube.com/watch?v=uWDocIoiaXE</a>
How can we also add images to the supabase database. If documentation that we are looking at has images that explain, is there a way to include the image in the chunking?
You could have the LLM generate a description of each image and put that in the chunks! Otherwise you&#39;d probably have to store the images separately, and then include a reference to the image name in the chunk. So when the LLM pulls that chunk and sees that image name, it could use another tool you create to fetch and analyze the image.
I&#39;m also a professional developer and must say this is by far the best video on coding I ever watched. Perfectly structured, everything is smooth and in a perfect tempo.<br>If you have the chance you should become a prof at university haha. Joking. I just got into AI deeper a few days ago and already messed around with a bunch of things. Now I&#39;ll try this and build my own AI agent army :D. Unfortunately the video was soooo good, I did not code with you on the side, but thanks to that I understood everything perfectly and since you provide the repo it is just awesome.<br>Thanks so much and keep that amazing work up mate :)
Wow that really makes a lot, thank you! I was a TA back in college, probably wouldn&#39;t become a professor though haha
@@ColeMedin I also was ta or directly translated it would sound something like academic co worker haha.  I&#39;m sucking up your videos currently and that even gave me some hope to find something interesting in my 9 to 5 instead of the boring day to day coding. And maybe that even opens new doors to get out of that. Just incredible times in regards to tech. Not in general good times but it gives a glance of hope for a better future for my kids (hopefully) üí™üèª best wishes from germany
Super solution, I depoled it in GCP. A piece of good work, please consider whether to take the next step to run this agent right away test and prepare the environment to test them with this application.<br>This would make it possible to assess the quality of the agents produced on an ongoing basis.
Nice job getting it up on GCP! Love it.<br><br>I appreciate the suggestion too! Having Archon actually verify the agent as a part of an iterative development loop is something I want to build out in future versions for sure.
What‚Äôs a bit confusing is you do this video and then the next video is your package that doesn‚Äôt have these same things in it, so which is best ü•≥
Yeah I understand the confusion there! My local AI package contains a bunch of services (Ollama, Supabase, Open WebUI, etc.) but not frameworks. Frameworks like Pydantic AI and LangGraph are simply Python libraries you install and use to leverage services like Ollama for your LLMs and Supabase for your database. See the difference there? They are different categories - Pydantic AI and LangGraph aren&#39;t Docker containers I could include in my stack. But you can certainly create a Pydantic AI and LangGraph agent that uses this stack for the DB, LLMs, interface, etc.<br><br>I hope that helps!
Thank you so much for everything you are doing for the greater good. This is the FIRST agentic system I have successfully got to run. However, I ended up having to use Ollama, I was getting errors with OPENAI (&quot;openai.BadRequestError: Error code: 400 - {&#39;error&#39;: {&#39;message&#39;: &quot;Unsupported value: &#39;messages[0].role&#39; does not support &#39;system&#39; with this model.&quot;, &#39;type&#39;: &#39;invalid_request_error&#39;, &#39;param&#39;: &#39;messages[0].role&#39;, &#39;code&#39;: &#39;unsupported_value&#39;}}&#39;).  Regardless Im super excited to see what you come up with next. Have an amazing day.
You are so welcome! Glad you have it up and running successfully!<br><br>Are you using o1 or o1-mini by chance? Those models don&#39;t support system prompts unfortunately, but o3 does.
@@ColeMedin Yes I was using o1-mini and preview.
Yeah that&#39;s it then! You could switch to o3-mini or gpt-4o
@cole look up MCP servers you can create one that people can use in vs code with roo code/cline and other extensions and the server can give the tools the pydantic knowledge
Absolutely incredible Cole. This is a game changer.
Thanks man!
just for me to understand.. shall this substitute n8n or what is the advantage from this approach over n8n which you used to work with before a lot ?
Great question! I still love n8n and use it all the time, I think it&#39;s the best no/low code platform out there. In the end though, I feel like I have much more control when I code my agents with frameworks like Pydantic AI and LangGraph instead of using a workflow builder. That&#39;s why I generally prefer something like this over n8n when I&#39;m building more advanced agents.<br><br>Essentially:<br><br>- n8n is easier to work with but less flexible<br>- Coding frameworks like Pydantic AI are more flexible but also you have to know how to code
My mans doing gods work
thank you ! i appreciate <a href="https://www.youtube.com/watch?v=U6LbW2IFUQw&amp;t=464">7:44</a>
You bet! I appreciate you calling that out!
I did some research on the llama and pagetic and it seems there are other cases where the streaming breaks because of json issues
Interesting! Hope they fix it soon
I could definitely see making an angelic rag around model context protocol so that that stuff is just understood by the agent. I think getting to that point as fast as possible. It is critical right now the LLMs don‚Äôt even know that it exists similar to the pydentic. I think you could make a generalized worker agent that‚Äôs able to do so much just give an MCP.
Agentic RAG with MCP is a great idea and I&#39;m actually working on making Archon an MCP &quot;subagent&quot;!
@ by subagent you mean you would implement it as an mcp server ?
Yeah exactly!
will be a good idea to take small breaks between sentences. Pretty hard ot follow with continuous speaking.
I appreciate the feedback! Any specific part of the video or just the whole code walkthrough mainly?
@Cole Hey man I have been watching your videos for a few weeks now and they are very cool. I tried to get your Archon running and was almost successful. The only thing I am missing is a $200 subscription to o3. <br>could you add Google Omini Studio to your readme? Its mostly free and I tried to add it but don&#39;t know where to find the URL. (the docs are confusing)<br>keep up the good work. FYI I am just a pilot and not a coder and I can mostly follow along..
reasoner run prompt=<br>    User AI Agent Request: Build me an AI agent that can answ...o creating this agent for the user in the scope document.<br><br><a href="https://www.youtube.com/watch?v=U6LbW2IFUQw&amp;t=44733">12:25:33</a>.462   preparing model and tools run_step=1<br><a href="https://www.youtube.com/watch?v=U6LbW2IFUQw&amp;t=44733">12:25:33</a>.464   model request<br><a href="https://www.youtube.com/watch?v=U6LbW2IFUQw&amp;t=44756">12:25:56</a>.771   handle model response<br><a href="https://www.youtube.com/watch?v=U6LbW2IFUQw&amp;t=44756">12:25:56</a>.782 pydantic_ai_coder run stream prompt=Build me an AI agent that can answer questions about code in a GitHub repo I give URL to<br><a href="https://www.youtube.com/watch?v=U6LbW2IFUQw&amp;t=44756">12:25:56</a>.783   preparing model and tools run_step=1<br><a href="https://www.youtube.com/watch?v=U6LbW2IFUQw&amp;t=44756">12:25:56</a>.785   model request run_step=1<br><a href="https://www.youtube.com/watch?v=U6LbW2IFUQw&amp;t=44759">12:25:59</a>.787   handle model response<br><a href="https://www.youtube.com/watch?v=U6LbW2IFUQw&amp;t=44759">12:25:59</a>.788     response stream text<br><br>This is my logs, here we can see its not going to route_user_message and to other steps 2 and 3, why is this happening.?<br>Due to this I am not seeing and output on screen.!
Are you running Archon from the v2 folder or the root of the repo? I think there might be a small bug I need to work through. Also which version of Python are you using?
Yes I am running archon from the v2 file<br>And using Python 3.11.7
Thanks for the info! Which model are you using too? Sorry forgot to ask that
I am actually using gpt-4o-mini and o-3 through openrouter
We are a high tech property management company.  I would love to find someone to help us build some cool ai agents.  We have SOP&#39;s in place, we are highly evolved, which means we are very clear on what we need, which will help with ai agents as we specifically know what we need.  Would love to work with you or if you could guide me to someone who could help do this.  So cool man!
I appreciate it! I don&#39;t offer consulting services for buidling AI agents right now but I&#39;ve got a community of devs over at <a href="http://thinktank.ottomator.ai/">thinktank.ottomator.ai</a> so you could make a post there!
Cole, do you build agents for people?
I don&#39;t currently since I&#39;m so busy with my YouTube channel!
Man, I have 15 year of experience as a web-developer and I&#39;m very impressed with then content on your channel! Keep up the good work! Do you you have any courses on these topics?
I appreciate it a lot! Got a course coming out within the next few months actually!
Amazing !
Excellent work. Subbed!
nice how do you load the agents and use them after creation with langraph?
The agent can give instructions for running agents! Typically it&#39;s just installing the necessary Python packages and then running the agent with Python. You could use something like Streamlit to make an interface to talk to the agent as well.
Cole - keep up the great work. You are my go to for not just AI explainers but also insights and practical examples. There is a lot to know and you make it easier.<br>Next task create an AI Agent to consume your channel and absorb insights and patterns.
Thanks Simon, I appreciate it! Let me know if you build that agent haha
Thank you so much for making this video! I appreciate the ‚Äúnon-coder‚Äù consideration. I hope that helps grow your audience fast, and it‚Äôll let me continue to share your content with others like myself!
I wonder if including meta tags e.g. beginner, no-code, in the description would help draw those like myself who want to do technical things but don‚Äôt have the background experience.
You are very welcome! Thanks for calling that out!<br><br>I appreciate your suggestion in your reply too, sounds like a great idea.
not local, need API
Only for the embedding model! Which in a future version of Archon I will be making it possible to use a local embedding model as well.
Cole, what do you think about the AGNO library? <br>They say it is 10,000x faster than LangGraph!
Couple others have mentioned Agno so I took a look - seems impressive and I love how simple it is! Certainly a higher level of &quot;abstraction&quot; though so you have a lot less control than something with LangGraph. In the end both frameworks are very fast.
HUGE VALUE!
You are an excellent teacher! Hard to do well!
Thank you Liz!! :D
I see below that you tried using both the langgraph and pydanticai docs together and you got too many hallucinations. What about adding pydanticai github repos? Heck youtube videos that go over pydanticai builds. Essentially any other resources to help inform Archon.
Cole this is incredible and I can&#39;t wait to play with it. I came the conclusion that I needed to so something similar. I am just a beginner but, I am thrilled to say I actually understand what you are doing! This process is WILD.
I appreciate it a lot Liz! I&#39;m glad it is clicking with you too!
Am I missing something? Why don‚Äôt I see the ‚Äúhuman in the loop‚Äù in the demo at the end?
My example was pretty short in the end so I didn&#39;t cover that piece for the sake of brevity. Thinking back on it though I definitely should have gone through a full example and I will for future Archon videos!
What fantastic content, I am a software engineering student, and I would like to ask you to make a video of the deployment step by step? Hugs from Brazil.
Thanks man! For deploying this, I would recommend containerizing it with Docker and then deploying to a service like Render, which I cover in this video:<br><br><a href="https://www.youtube.com/watch?v=2Ai7_5G70xY">https://www.youtube.com/watch?v=2Ai7_5G70xY</a>
man amazing video fr, but pls use dark mode for LangGraph u burned my retina üòÇ
I appreciate it! And yes very fair suggestion haha, I will certainly do that for future Archon/LangGraph content
@@ColeMedin ‚ù§Ô∏è‚Äçüî• keep it up bro
dear Cole, thanks a lot for your work on Archon!<br>I have and openrouter account, and I would love to run the V2 Archon iteration using R1 as the reasoning model and Qwen 2.5 14B instruct as the main coder module. I have also OpenAI API credential for the embbeddings.<br>However, when I try to setup this configuration in the .env, i cant manage to sort it.<br>Can you or anyone please tell me how should i do it please?
You are very welcome!<br><br>When you say you can&#39;t sort the .env, where are you getting stuck exactly? You should be able to see the LLM API KEY environment variable to your OpenRouter key and then change the base URL environment variable to the example I have in .env.example for OpenRouter!
Bro, I have a question.<br><br>At minute <a href="https://www.youtube.com/watch?v=U6LbW2IFUQw&amp;t=2370">39:30</a>, you mentioned that you implement human in the loop by interrupting the flow and using Streamlit to get human input. However, you also said there‚Äôs another way to do it, which involves ‚Äúturning off‚Äù the graph and then inserting the new message from the beginning of the graph. Could you explain how to do that?<br><br>I want to apply it in a serverless environment. I‚Äôd like to know how I could save the state, ‚Äúturn off‚Äù the graph, and when the expected message arrives, ‚Äúturn it back on‚Äù with all the previous information and continue from the node and state where it left off with the new message.<br><br>I‚Äôd really appreciate your help. I‚Äôve been trying to solve this for days and feel a bit stuck on this topic.<br><br>...<br>Keep up the amazing content! I‚Äôm really excited and can‚Äôt wait for the next video on Archon‚Äôs next iteration üî•.
Thank you for your support! And great question!<br><br>I didn&#39;t quite mean to say &quot;turning off&quot; the graph if that&#39;s exactly how I put it - I more meant another method is having the entire graph execution be just a single agent message in the conversation versus my implementation is a single execution of the graph manages the entire conversation if that makes sense.<br><br>For both methods you can completely &quot;turn off&quot; the graph and both will work in a serverless environment. The big caveat is you have to change the &quot;MemorySaver&quot; I have defined at the bottom of the graph script to be a SQLite or Postgres memory saver instead of the basic in memory one, otherwise you would lose the current graph execution state in a serverless environment. See this section in their docs for the different memory savers:<br><br><a href="https://langchain-ai.github.io/langgraph/concepts/persistence/#checkpointer-libraries">https://langchain-ai.github.io/langgraph/concepts/persistence/#checkpointer-libraries</a><br><br>Essentially the current state of the graph for each &quot;thread ID&quot; will be saved in the database, so even if the graph is resumed after the human intervenes and it&#39;s in a serverless environment so it&#39;s a totally different machine, everything will still work and all the state/current node in the graph will be pulled from the database.<br><br>I hope that helps!
@ColeMedin¬† Ufff, perfect! Now I totally get it. I&#39;ll have to go through some trial and error to see if I can make it work because I wanted to use a saver that‚Äôs more like NoSQL, so I could integrate it with Firebase or something similar. But with the information you provided, this helps me a lot.<br><br>It would be awesome if at some point you go deeper into the topic of savers. Either way, with this, I already have a solid base. Thanks a lot, bro! üòé
I&#39;m glad! You can make custom savers, the LangGraph docs has an example of creating one around Redis. Doesn&#39;t seem super easy but it is doable.<br><br>I definitely want to go deeper into savers in a future video when I include the Postgres saver for Archon! You&#39;re welcome man!
Bro, congratulations üéâ. Your content is amazing; I‚Äôm truly impressed ü§Ø. I‚Äôve been into generative AI for 2 years now, especially in LLMs, and I‚Äôve seen how the technology has evolved. I‚Äôve watched thousands of videos and followed many YouTubers, but believe me, you‚Äôre one of the few whose content I‚Äôve loved and found genuinely useful for my AI projects. I admire you a lot. Congratulations on such incredible work üî•.
Wow that really really means a lot to me, thank you so much!! :D
This is amazing! Well done Cole. I do have a concept of an agentic system, which I would love to talk through with you to get your take on it. Would love to connect in private.
Thanks man! I don&#39;t have a ton of capacity to dive into other projects at the moment but if it&#39;s just some questions you have, feel free to email me with the email in my bio!
@ perfect. Thank you! Will do!
You bet!
<a href="https://www.youtube.com/watch?v=U6LbW2IFUQw&amp;t=2630">43:50</a> ‚Äú‚Ä¶l&#39;ve taken the time to figure all of this out for you!‚Äù Bravo üôå Thank you! Very helpful for a non coder like me.
I appreciate you calling that out Joshua! You are very welcome!
Non coders, unite!
so odd - 80k subs, 30k+views and only 14 watching on github??? wow... I am - just cloned and am playing... well done with the vid. Love the details.
People tend to star the repo a lot more than watch it. I appreciate the kind words a lot!
now can we use deepseek to reson instead of openai?
You certainly can! I show in the video how to use Ollama instead of OpenAI and you can use the R1 Distill models locally! Or you can use the full R1 through OpenRouter.
Can you do a full tutorial? Like with a blanco machine.....
This is what i&#39;m talking about, a real OG project. Please complete this project and all phases. Looking forward to this.
I certainly will! I appreciate the encouragement!
hey can you cover swapping out ollama for lm studio for easy mlx use on macbooks?
You should just be able to change the base URL environment variable to point to the URL for LM Studio!
Great vid. Why pydantic instead of smolagents? And why langgraph instead of n8n? Asking out of curiosity. Thanks
Thank you Ruben and good questions! I enjoyed using Smolagents a lot and covered it in a video I made a couple videos before this one. But in the end I felt like everything was too &quot;abstracted&quot; - it made things simple at the expense of I didn&#39;t really have the control I needed to customize things to my liking which I do with Pydantic AI.<br><br>LangGraph and n8n I wouldn&#39;t say are super comparable. n8n is a no/low code AI automation tool while LangGraph is a framework for orchestrating agents together in an agentic workflow. You can use n8n to string together &quot;AI Agent&quot; nodes so I suppose you could sort of replicate LangGraph functionality, but LangGraph offers so many features that would be difficult to include in n8n like global state management, human in the loop interactions (being able to pause indefinitely in the middle of a workflow), etc.
@ColeMedin¬† thank you. I&#39;m sure you&#39;ll miss at times the code agent approach of smolagents :)
Yeah it is a good approach! Did feel unnecessary sometimes though
damn u are the best Cole Top Content that why ur followers increase so fast. deserved!
I appreciate it a lot!
Cole, this is exactly the AI stack I was looking at too. Feels like next to bare metal prompt chaining LangGraph is definitely the way to go for lowlevel control. How would Cursor be at building out if you feed it both pydantic and LanGraph docs?
I actually tried Windsurf with the Pydantic AI + LangGraph docs (I assume Cursor would be similar). It did pretty well but hallucinated on a couple things and was pretty inconsistent with the structure of the code it produced when I had it make a few different agents.<br><br>My main goal with Archon is to make it better than just using an AI coding assistant with the docs is to give it really good instructions on the code structure and include parts to the agentic workflow for things like a self feedback loop on each aspect of the agent to avoid common hallucinations I see when using something like Cursor.
@@ColeMedin I think its a great idea and I&#39;m gonna follow Archon closely, because an IDE approach for agentic flows is exactly what we need right now. When to model switch, when to feedback loop, etc. Its a whole other animal than a straight full stack codebase. Keep up the great work brother.
Langsmith integration with Archon would definitely be the play imo. Would take care of the visual element which is huge for graphs.
Thanks man and I appreciate the suggestion too! LangSmith is great - already on the list for future integrations I want for Archon!
How does this fare with regard to agno repository?
I took a look at Agno recently and I appreciate the simplicity it offers - reminds me of CrewAI a lot. But I feel like it&#39;s such a high level abstraction that you miss out on a lot of the power and control a framework like LangGraph gives you. Also both frameworks as so fast that the speed comparisons seem like an irrelevant point unless you need a VERY fast AI agent.<br><br>Curious to hear your thoughts too!
@ColeMedin¬† You are right, the speed is not important at least for the current real world use cases. What I would want is a more comprehensive agent for example an agent tool that can combine agno or yours with tools like browser agent and cline, i.e. it should have access to more resources like browsers and terminals and should be able to handle them reliably.
I thoughhavinglanguage barrier. 100 percent appreciate your work. thanking you. keep it going
Is it possible to have the agent to save the scripts and execute automatically to have a feedback loop? It would be cool to have it debug automatically as well.
That is one of the end goals for Archon! Certainly is possible.
Cole, I have not coded for years (I am from a different era). Your teaching and knowledge is phenomenal!  I look forward to every piece of content you put out. I consume much YT content on AI and you are in a league unto yourself.  Thank you for sharing your gift and talent with me, and the world.
That is super kind of you to say! I really appreciate it!
Splendid walkthrough. I really hope we get more of these!
Great explanation, can&#39;t wait for future iterations of Archon
Thanks!
You are welcome! Thank you so much for your support! :D
Thank you for creating such an insightful video on AI agent development‚Äîyour detailed explanations and practical examples were incredibly helpful! Looking forward to more of your expert content.
Thank you - I appreciate it a lot!
Fantastic video and content as usual mate, keep it up. When it comes to actually scaling AI to production, your content is unique. <br><br>One question/pushback: you mentioned correctly early on about the concept of simplicity and only using a nail gun if you need a nail gun, this isn‚Äôt just an AI concept, it‚Äôs a general backend concept that everything should be as lean &amp; DRY as possible to get desired outcome. <br><br>With all that being said, could one not argue that this is the EXACT use case for tools like CrewAI, that essentially allow you all the complexity you will truly ever need at a high level, and anything finer details can be ironed out in Python code directly? <br><br>CrewAI integrates with Pydantic data validation library quite seamlessly, yes they have their version of ‚ÄòGraphs‚Äô with their higher level ‚ÄòFlows‚Äô but I‚Äôd struggle to find a production grade direct to consumer app that would ever need more complex AI workflows than this stack provides. <br><br>One could argue for extremely sophisticated systems like ones discovering new science, handling regulated data etc etc. you‚Äôd need complete control, however most people watching this are not building these systems. <br><br>Interested to here your thoughts on this
Thanks for the kind words and I appreciate the well thought out question + pushback too!<br><br>I definitely appreciate the simplicity of CrewAI - I totally get where you are coming from that a lot of times the level of abstraction CrewAI gives is acceptable and it makes everything simpler while still giving you all the control you need.<br><br>At the same time though, I can certainly think of production use cases where you do need more complex AI workflows that CrewAI provides. The level of control that something with more low level abstractions like LangGraph can provide. I&#39;m building out Archon to clearly be one of those examples. The way it handles state, memory management, human in the loop, etc. is just so powerful and a higher level framework meant to just connect agents together can&#39;t really do the same thing, or at least not with making it just as complicated in the end.<br><br>I hope that makes sense! Definitely feel free to keep pushing back too, I sure don&#39;t mind!
This is really great and high quality content! Thank you!
You&#39;re very welcome! Thank you!
What&#39;s the difference between using this and just uploading docs into Cursor and asking it to reference that instead?
Good question! So I&#39;ve tried just referencing the Pydantic AI/LangGraph docs right in Windsurf and Cursor and it does pretty well, but still hallucinates a lot. <br><br>The goal of Archon is to build out a more full agentic workflow specifically designed to create Pydantic AI/LangGraph agents that will avoid the common hallucinations when you just give the LLM in Cursor/Windsurf the docs and ask it to build. Archon will be instructed with specific guidelines for the code it produces, have a feedback loop to evaluate each part of creating the agent, and I even eventually want to make it so it can actually spin up and test the agent in real time!
@ I see, thanks for the response Cole. That‚Äôs a great idea; you can essentially make the cursor of building ai agents. There‚Äôs a reason why cursor is the fastest growing saas this year!
You bet! Yeah exactly!
Sweet video!  I devoured the n8n videos and built a RAG prototype for my company.  Amazing results. Now I&#39;m thinking of using this for the real deal.
Great job. I am developing a program that i want to integrate these exact features in. Are you interested in working on it?
Thank you! I don&#39;t have capacity to take on other projects right now though since everything I&#39;m doing on my channel is taking all of my time! Feel free to contribute to Archon though if it&#39;ll help your project :)
Great Video!<br>I want to create an eCommerce chatbot help with crawl4ai + pydantic AI supabase for RAG etc...<br>Could you advice me what tech stack to choose? What should be the AI workflow?<br>I will really appreciate that
Thank you! Could you be a bit more specific with your question? Which part of the stack are you wondering about and what options are you considering right now?
@ColeMedin¬† Crawl4ai (DeepSeek) for scraping the eCommerce, storing the data in supabase / self hosted PG +  PG vector using openAI&#39;s embeddings model<br>And pydantic AI as the agent <br>Anything I&#39;m missing?<br>What is the best flow?<br>&quot;User enters a query&quot; -&gt; &quot;Rephrase and sanitize with AI&quot; -&gt; Embeddings -&gt; supabase -&gt; pydantic AI semantic search<br>Sound good?
I&#39;d say if you are leaning local I would use an embedding model that&#39;s local through Ollama like nomic-embed-text!<br><br>That is a great flow though - sounds perfect to me.
Hello Cole, thank you so much for your amazing videos! I&#39;m new to AI agent development, and your content has been incredibly helpful in expanding my knowledge. I have a fundamental question: Why do you prefer using Pydantic AI with LangGraph instead of LangChain with LangGraph? What makes Pydantic AI a better choice for you compared to LangChain? Best regards from Germany!
You are very welcome, I&#39;m glad my content has been helpful for you man! Great question too. The main reason I prefer Pydantic AI over LangChain is for the same reason even the founders of LangChain say it isn&#39;t production ready - it&#39;s kind of a mess of various prebuilt modules/black box tools, legacy implementations, and abstractions that just make it a harder framework to work with compared to something super clean like Pydantic AI.
Thank you Cole for this video. It is something I was brainstorming about for sometime, I think we are on the same wavelength :) Question: How did you create the supabase used as the tool for the pydantic ai documentation? It would be interesting to create additional documentations for additional libraries.
You are so welcome!<br><br>Could you clarify your question? Are you asking how I set up Supabase? I do have instructions in the README for setting up the tables with a SQL script if that is what you mean!
When I got started, I kind of over-rotated on the whole self hosted thing, so I do everything locally.  <br>For embedding, I used nomic-embed-text which is a 768 vector.  I am in the process of modifying your code to handle this, and if I can get GitHub to show me the changes I will link you to them.  One early gotcha is changing the vector size reference for both saving and searching.<br>And one (I believe) miss on your part is that you say somewhere on the repo to have all the stuff called out in scope, but I have not found scope that says to crawl langgraph or give the changes needed for crawl_pydantic to be modified.  <br><br>Keep up the great work!
So in the demo wasn‚Äôt finished? We wear at the output state of the code agent and request a user input correct, would have been cool to invest the 1-2 extra minutes to show the loop by telling it that it missed the Open API key in the env variables and then say in the next message that all looks good.
Yeah I wanted to be concise which is why I stopped without going through the full agent creation, but I totally get it would have been nice to see the final agent it created. In future Archon videos I&#39;ll actually be going through the full agent creation and demo process!
@@ColeMedin forgot to mention, great work thanks for that :) and keep pushing forward. My first suggestion would be to auto verify the python code by a ‚Äûexecution‚Äú agent or tool to at least iterate if the has syntax errors and so on. But I think you plan this with V3 anyway?
Great suggestion! Yes I am planning this in the future. Maybe not v3 but certainly within the next few versions.
great overview... not a step by step demo .... @22mins references a git page that shows how to set things up.... then 20mins of analyzing code ... and @48mins a demo of using it.
i followed the readme on the main git page... i think its the same as the readme in teh video @2300 (which is in a subdir). they are almost the same.... almost (a few extras in the video version)
Sorry it&#39;s a bit hard for me to understand what you are saying - are you saying I should have prefaced the video in a different way? :)
@4900  &quot;openai.NotFoundError: Error code: 404 - {&#39;error&#39;: {&#39;message&#39;: &#39;The model `o3-mini` does not exist or you do not have access to it.&#39;, &#39;type&#39;: &#39;invalid_request_error&#39;, &#39;param&#39;: None, &#39;code&#39;: &#39;model_not_found&#39;}}   ,,,,,,,,,,,,,,, i think this is caused by a tier 1 user (like myself) not having access o3mini... does anyone know a good workaround?  i just need to see the setup details done once.....
@@ColeMedin i am stuck on one thing... and not sure what it is, because did not see it all being setup in the video.  the details. would only take 5 mins max. if i cant get it running on my pc, then its not interesting... ok, maybe i am not you target audience... <br>I ran into the same problem with another vid, o3-mini refusing... thanks anyway
Try using o3-mini through OpenRouter instead! I think you need a higher API tier to access it directly through OpenRouter.
GOOD JOB...Merci pour le partage, et tu as oubli√© de mettre le doublage audio pour nous les fran√ßaisüòâ
Hell yeah. I&#39;ve been waiting for your take on this. Thanks brotha!
You are welcome man!
Why does every video from you say ‚ÄùX is the best way to build AI agents‚Äù and it&#39;s different every video? <br><br>Some consistency would be nice instead of every title being click bait. It&#39;s difficult to believe you when you change your assertions in every single video.<br><br>As a person who is new to AI, your content is terrible as a guide, because every video tells us to use something different to do the same thing, each time calling it the ‚Äùbest‚Äù way.
I totally understand where you are coming from. Titles are tough for me sometimes haha, but it&#39;s actually really hard to make a title that speaks well to the content but also will do well with the YouTube algorithm. And if I focus on just making my titles entirely practical then my videos get a lot less views, so I have to balance click bait with it being as realistic as I can.<br><br>After reading your comment I did go back through my titles and the only other recent examples were Flowise + n8n for the best no code AI agent combo (which I still think is true for no code), and then other videos with Pydantic AI. It&#39;s a bit of a stretch I will say, but I do consistently use this kind of language with just Pydantic AI so I hope that counts for something haha.
@@ColeMedin Sadly true.  Most other YouTubers with AI content say &quot;Just join my school for access to code&quot; but Cole has kept everything ACTUALLY free, with warnings about what can&#39;t be (i.e. in this video to use OpenAI for embedding) so I think the click-bait-ish titles are the lesser price to pay.
Facial hair on point bro üî•
Haha I appreciate it!
Can you please a playlist out of this series, much appreciated your effort :)
Yeah I&#39;ll make a playlist for Archon and Pydantic AI/LangGraph stuff after the second video is out!
You are absolutely the best teacher and content creator for AI agents! Especially mentioning the glitches where writer suddenly came from etc (was already looking for it during the video).
Thank you, that means a lot! Yeah I always try to cover the little things that got me stuck, I appreciate you calling that out!
I&#39;d like to see a solution that can actually handle caching and rate limiting. Especially necessary for implementing any kind of RAG agent.
There is so much overhead to managing conversations in a pure pydanticAI implementation. Langgraph is the way
So clear!!! Learnt heaps!!
I&#39;m glad!! :D
Excellent tutorial, thanks. I had to drop Pydanticai because I could not implement a multi-agent pipeline I was thinking of (mostly assisting as chatbot agents). I think is just not meant for that.
Thank you, you are welcome! I feel like Pydantic AI would actually be great for your use case, what specifically didn&#39;t work well for you?
Great video and very helpful. I had just started playing around with LangGraph / PydanticAI integrations. Thanks again!
Thank you! You bet!
Nocode please üôè
More no code content around things like this coming soon :)
@ColeMedin¬† Awesome thanks üëçüòä
You bet!
I just looked at the weather agent code at the beginning, and it seems unnecessarily long and complex just to get weather data from an API. However, I&#39;ll continue watching the video to learn more.<br>By the way, there&#39;s another great video on multi-agent systems and using DSPy. It explains how to use DSPy to improve prompts, which are crucial for agents. It also discusses the future of AI prompting and fine-tuning. No more need for prompt engineer or human approval. With current agent, most of ttokens are for wrongresponses of the thinking or agentic process.<br>Here‚Äôs the link: <a href="https://www.youtube.com/watch?v=39ZUJsrazao">https://youtu.be/39ZUJsrazao?si=M4TMzmf-m5WqCQr1</a>
Yeah it&#39;s just an example, not meant to be an incredible agent that solves a big problem!<br><br>DSPy looks super interesting, thanks for sending that my way!
@ColeMedin¬† yes i found your own exemple simpler and more clear.<br>Yes, look at the Multl-agent &amp; DSPy, one of the best video about agents. Check his videos, one of the most up to date on LLM and AI advanced subjects. I think he is working at IBM
@ColeMedin¬† this was the TextGrad method but today, he is talking about a better method, the SiriuS method. All can be found on Youtube, Github + papers on arXiv.
Perfect as always‚Äîclear, easy to understand, and simple to implement. Your contribution to the AI community is immense, and I deeply appreciate it. If you could integrate a speech-to-speech AI assistant into the AI framework, it would add even more value. Thank you!
I appreciate it a lot! I definitely want to do more with voice agents so I appreciate the suggestion!
‚Äã@@ColeMedin thank you for replying back to my request, i have another question i tried to modify the code to accept the embidding from ollama the model is pge-m3:latest however it will say that it cant find the model, evenhough i checked multiple times that i can access both the reasoning and the primery model as well the embidding model from the Virtual enviroment. note i am running ollama part of the ai pakaged kit stack.
Another gem dropped ! I&#39;ll save it for later, time is missing üò¢
Thanks!
You are welcome! Thank you so much for your support!
Keep the awesome content coming!  The level of detail in the instructions is appreciated.
I certainly will! :)
Rad
PydanticAI + LangGraph + Knowledge Graphs  (Neo4j) = Next gen AI Agents!
Man I&#39;m Senior Backend Developer with 8 years of experience and I can tell you have the best content for AI Agents! Please keep delivering this high quality content! I really appreciate it!
Wow I appreciate that a lot. Thanks man - you bet!
Hey quick question from a beginner Software Developer to a Senior one: do those AI agents be built to excel or be at the same level as a senior-level engineer? I‚Äôve dabbled with having AI in the past, taking on certain persona but I have never done something like building an AI agent. Just asking for a ‚Äúfriend‚Äù lol
yeah I am learning a lot lol... I just dont have the time to do it all myself! I need people like this that can take my workflows and help automate them - spend the time to build these agents and automations...
Certified !
Hi Cole, been following you for a while and must say your videos have become of highest class, very clear and friendly tone, which is nice for a semi-beginner like me.<br><br>I was wondering whether there is any chance I could discuss a project i&#39;m working on with your, just on approach of the agent build and whether it&#39;s overkill or not?<br><br>Thanks in advance, and again, great video!
Thank you, I appreciate it a ton!<br><br>If you want to make a larger post about a project you&#39;re working on, you could put up something in my oTTomator Think Tank community: <a href="http://thinktank.ottomator.ai/">thinktank.ottomator.ai</a><br><br>And I&#39;ll definitely respond there!
