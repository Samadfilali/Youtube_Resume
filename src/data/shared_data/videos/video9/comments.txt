Thank you for sharing such a great work! Great explanation and thank you for covering the little tricks and details which otherwise are hard to fix. A note to everyone who tries this for the first time - in order to test the node that deletes duplicates you first need to setup the database.
soooo... I think Ive missed something on the other videos, but, what if I want to develop something localy using something like cursor with the intention to deploy it online. It would be easier to use supabase on the cloud right?
New viewer here,<br><br>I like the content in general, I&#39;ve watched a lot of different videos from you but it feels like you playing too much into watch time. For this one I got bored and just used a free youtube summariser and got all the info I needed in 30 seconds (I see irony) but if you are open to some honest feedback, please get to the point quicker. <br>(I gave up on the <a href="https://www.youtube.com/watch?v=pOsO40HSbOo&amp;t=170">2:50</a> mark).<br><br>Regardless, thank you so much for sharing!
I already had a n8n-import and qdrant container so while running this setup getting the error to either remove or rename that container. But been unable to rename it and dont want to delete the existing container as i have a lot of projects there already. What should i do.?
Great guide, appreciate the work you are doing! I&#39;m completely new to all of this. Had a question - In my guide to attaining knowledge I came across anythingLLM and the ability to also to host it locally. Wanted to know your thoughts and comparison of the two.
Thanks, making it work in my local is probably the best thing I did in 2025!
AI Agent + RAG + Run Locally tutorial will be lit🔥
Okay, so I&#39;m a big local fan, and spent the past 2 days trying to get supabase running under my Unraid instance, and I finally got it using compose-manager (the GUI for compose in unraid)<br>Not that a lot of people are trying to do this, but here was the magic sauce for me. YMMV and I may have forgot something while doing this, but good luck :)<br><br>Create SupaBase folder in unraid app folder<br>mkdir /mnt/user/appdata/supabase/<br><br>inside supabase, git clone supabase. you&#39;ll end up with<br>/mnt/user/appdata/supabase/supabase<br><br>make a volume folder to store all of the docker files<br>mkdir /mnt/user/appdata/supabase/volumes<br><br>in the .env file I added a custom path to handle the volume<br>############<br># Storage - the Root volume Path for docker containers, no trailing slash. compose will have /volumes/name<br>############<br>DOCKER_VOLUME_PATH=/mnt/user/appdata/supabase<br><br>Then in the docker-compose.yml Update all paths for all volumes to use it:<br>    volumes:<br>      - ./volumes/storage:/var/lib/storage:z<br>Becomes<br>    volumes:<br>      - ${DOCKER_VOLUME_PATH}/volumes/storage:/var/lib/storage:z<br><br>Another change in docker-compose.yml, changing the db-config volume at the END of the file<br>volumes:<br>  db-config:<br><br><br>Becomes:<br>volumes:<br>  db-config:<br>   driver: local<br>   driver_opts:<br>     type: none<br>     o: bind<br>     device: ${DOCKER_VOLUME_PATH}/volumes/db/config<br><br>I was getting a lot of errors after the first time startup with vector and db that required some massaging.<br>1. touch /mnt/user/appdata/supabase/volumes/logs/vector.yml   to create this file so docker doesn&#39;t create it as a file.<br>2. edit /mnt/user/appdata/supabase/volumes/db/config/postgresql.conf and comment out the WAL-G, Replica and supautils configurations as DB wouldn&#39;t load until I did this.<br>3. copy /mnt/user/appdata/supabase/supabase/docker/volumes/* to /mnt/user/appdata/supabase/volumes/<br>4. chown all contents inside the volumes folder to your correct user.  for me when the data folder was created it was 105:root so I just chown 105:root * -R so all of the containers had permissions to read write correctly.<br>5. compose up from the Unraid UI.<br><br>hope this helps someone.
love this era of ai
What are your views on Typesense? Like for Vector Search/Storage
I haven&#39;t actually tried Typsense before! What are the advantages to it that you see?
this is such a great video I would otherwise know where to start!! i tried to follow along but i keep getting &quot;password authentication failed for user &quot;postgres&quot;&quot; error when trying to set up credentials for postgres account in n8n and i am 100% sure i am using the exact password that i have defined under POSTGRES_PASSWORD= in the .env file. any ideas pls?
I appreciate it! Maybe the user is different? Did you change that value? Otherwise I&#39;m not really sure
@@ColeMedin  took couple of hours but i finally got it resolved, the password does NOT support special characters, and changing the password in .env then issuing docker compose down the docker compose up doesn&#39;t work because even though everything will be redownloaded, it get stuck at waiting for supabase-analytics. finally i have to remove the entire supabase git repo, and rerun python start_<a href="http://services.py/">services.py</a> to clone the repo from scratch
I dont understand any of this but it looks cool!! What can your agent do? Practical use case?
Haha glad it looks cool! In this video I built just a super basic RAG agent, but essentially these kind of agents can learn from your documents and answer questions using them as a reference point. So you can for example create an agent that takes all of your meeting transcriptions so later on you can ask it about past meetings you had if you&#39;re trying to recall something.
Tak!
Thank you for your support!
I wish you provided a detailed courses covering everything. Im a IT consultant but not a developer so there is a lot of gap in my knowledge in the developer world.
I am actually working on a course now! It&#39;ll be on building AI agents and I&#39;m going to be going very in depth.
When I stop the localai stack and bring it down the ollama image remains active in Docker Desktop. Then when I try to bring the stack back up I get an error indicating that the network can&#39;t be found. It appears that the ollama image is looking for the network that it was associated with when it was spun up the first time. Does anyone know why the ollama image remains active even after the container has been brought down? The work-around at this point is to run &#39;docker system prune&#39; to deactivate the ollama image. At that point I can spin up the full localai stack again.
That&#39;s really strange! Glad you at least have a workaround for now. What are the commands you are using to spin everything up and also tear it down?
@@ColeMedin I was initially using start_<a href="http://services.py/">services.py</a> but decided to narrow things down by removing supabase and n8n from the mix and using the command line docker-compose &#39;up&#39; and &#39;down&#39; commands. Still no luck for several iterations but it&#39;s behaving better now. After adding supabase and n8n back to the stack I&#39;ve been experimenting for several hours and have only needed to run &#39;docker system prune&#39; once. Maybe it&#39;s a timing thing. FWIW... I&#39;m running Windows 11 on a 13th Gen i9 with 128GB of RAM. Thanks for sharing your work so generously. You&#39;ve saved me a ton of time and frustration.
Nice work. Thanks! Very informative and helpful to learn things quickly and hands-on. Got it running with some minor effort.<br><br>The included open-webui is directly connected to Ollama as I understand it. Is the intention to use the webhook for that interaction eventually, or do I miss something and that open-webui is intended to already connect to your model in n8n?
Thanks! Glad you have it up and running! Yes, Open WebUI is directly connected to Ollama. Then to get it to work with n8n, you can set up n8n as a webhook that you can use in an Open Web UI pipeline/function. I cover that in this video:<br><br><a href="https://www.youtube.com/watch?v=E2GIZrsDvuM">https://www.youtube.com/watch?v=E2GIZrsDvuM</a>
@@ColeMedin again, many thanks. Worked like a charm.
On my M3 Macbook there was an issue where the Watch Folder would only trigger and find .DS_Store files. I had to make the n8n trigger ignore /data/shared/.DS_Store and also in Docker set the Virtual Machine Manager to Docker VMM rather than Apple Virtualization Framework. Apart from that, great stuff! Thanks :)
Wow that&#39;s so random... how did you figure that out? Thanks for circling back and letting me know too! Helps a lot since I don&#39;t have a Mac so I can&#39;t test these things mysef.<br><br>I appreciate it!
@@ColeMedin It was hours of asking AI, nearly tore my hair out :) It was so worth it though. I&#39;m really grateful to you for your channel, its great.
intrigued if/how you might evolve to GraphRAG for this stack?
I would certainly consider it! Do they have a Docker container?
Thanks you so much Cole for your golden standard. I have it installed and correctly running it, took me half a day to eventually add kongo in the credential path in n8n for supabase. I have added crawl4ai and mattermost to the yml file and changed/cleaned the file to run on ubuntu 24.04. Keep up the good work, you have one extra follower :-)
You are so welcome! Nice additions!
Any ideas why I&#39;m not getting the &quot;documents&quot; table in Supabase (seen in <a href="https://www.youtube.com/watch?v=pOsO40HSbOo&amp;t=1187">19:47</a>)? The workflow fail because it&#39;s missing. I followed all the steps and I re-did everything several times... :/
Did you run the SQL script to create the documents table in Supabase like in the video? I&#39;d check Supabase and make sure it&#39;s listed in the tables too!
i&#39;m having a problem with the supabase step:. I can successfully connect using an http node to http://supabase-kong:8000/rest/v1/ with apikey and the secret key in the header; but any time i try in the supabase node, with your method with http://host.docker.internal:8000 or http://supabase-kong:8000 it comes back unauthorized. Any ideas?
do i understand how to deploy that on a server?
Could you clarify your question?
​@@ColeMedinsorry. I just don&#39;t have any clue about docker etc. what would i have to do and have to get that architecture running on a shared apache?
That stache is actually growing in nicely bro
Haha I appreciate it!
Hi Cole, I appreciate this all in one local setup strategy!<br>One issue I&#39;m seeing is when I cloned your repository to try this myself, I saw that the package doesn&#39;t contain the shared, supabase, and volumes packages. Did you need to push those changes to your repo?
When you run the script to spin up everything it creates those automatically! So they don&#39;t need to be in the repo.
Bro can you make a video in how to finetune a model on cloud and how to access that fine tuned model for production. Its rare to find a video on this.
I certainly want to make some content around fine tuning soon so I appreciate the suggestion!
Can you make a video dedicated to using Open-WebUI as the front end to n8n agents? I know you touched on it in another video but getting a more defined step by step version would be awesome! Thank you Cole!
I certainly could make another video on it! I feel like my last one was pretty step by step though, what do you think was missing there?
So I sorta got things to work but the table/scheme public.documents  doesn&#39;t exists. I created one but ran into errors latter. Do you happen to know the scheme for that table?
never mind I found more documents
Hah. I had grabbed your Archon project and attempted to have Cursor dockerise it and connect it to local Supabase. It got 95% of the way there as it plugged pgrest in between and then various issues. Please include Archon in the local AI stack!
Nice Simon! I do plan on including Archon in the local AI stack soon actually!
@ - great. I need to subscribe to your product roadmap to avoid wasted effort. Keep up the great work!
Ran into a problem, added http tool to request current time. First time asked time, ai requested, answer gets stored into chat memory, and it wont request new time anymore. Always takes time from first request  from chat memory, and outputs it as current time. How to solve this?
Yeah I&#39;ve had things like this happen with LLMs before! The best way to solve this is to update the &quot;system prompt&quot; in the n8n Agent node to instruct it to never reuse a time it gave previously in the conversation. Tell it to always use the tool to fetch the current time when the user asks, even if they have already asked.
Thanks, Cole! Loving the content—just recently discovered your videos, and they’ve been incredibly valuable. I really resonate with the design frameworks you propose!<br><br>I’ve been adopting LangGraph as my go-to tool for AI systems, and I truly believe it’s the best approach for production-grade applications. That said, the low/no-code solutions like n8n are super appealing due to their reduced overhead. I’ve even seen teams successfully run production systems by hosting n8n on platforms like Railway, Render, or DigitalOcean.<br><br>I see n8n as a powerful prototyping tool, but the transition from no-code to production-grade code feels unnecessary when tools like LangGraph Studio exist. As a developer, do you think I should fully commit to LangGraph, or does it still make sense to follow the n8n prototyping → code development pipeline? Have your design thinking changed?
Absolutely amazing information in one video, thank you so much 👍
How to make complete iOS apps in Xcode with Ai tools ? which tool is best and easy for the person that have less knowledge of coding ,giving references of famous apps UI images and give them text prompt to give functionality and other features.<br>any live links of iOS apps of yours ?<br>windsurf vs cursor vs VS studio ?  comparison , which tool is better for iOS apps making
I always have the best experience with Windsurf so I&#39;d recommend starting there!
100% useful, an amazing video. Thank you very much!
Thanks! Glad you found it helpful!
Hello thank you! great video! I would like you to include if possible the capability to read and format pdfs, excel files even if they are not all formatted as a neat table, and images
VAULT_ENC_KEY=your-encryption-key-32-chars-min ... in the .env fie,  is it possible it must be exaclty 32 chars? 128 chars did not work and for more testing the time is not there at the moment ;)
I didn&#39;t actually touch that environment variable in my testing so I&#39;m not sure! But if 128 didn&#39;t work I&#39;m guessing there is just a max (like maybe 64), or maybe you&#39;re right and it has to be 32.
The superbase container couldn’t be referenced by name because it was started from a separate compose stack. You could create a named network and use it in both compose files.
I actually do combine both stacks into the same named network with the &quot;-p localai&quot; flag in the Docker Compose command. It just wasn&#39;t working because I was trying to reference the wrong container in the Supabase portion of the stack.
Your content is very usefull. Thanks for your time.
I&#39;m glad you found it helpful! You bet!
Sweet. I was trying to make this and now I find out it’s free. Thx
Yeah you bet!
Getting this error:<br>I am running it on mac M1 pro<br><br> ✔ Network localai_default                   Created                                                                                             0.1s <br> ✔ Container supabase-vector                 Healthy                                                                                             6.0s <br> ✔ Container supabase-imgproxy               Started                                                                                             0.4s <br> ✘ Container supabase-db                     Error                                                                                               7.3s <br> ✔ Container supabase-analytics              Created                                                                                             0.0s <br> ✔ Container supabase-studio                 Created                                                                                             0.0s <br> ✔ Container supabase-edge-functions         Created                                                                                             0.0s <br> ✔ Container supabase-kong                   Created                                                                                             0.1s <br> ✔ Container supabase-auth                   Created                                                                                             0.1s <br> ✔ Container supabase-meta                   Created                                                                                             0.1s <br> ✔ Container realtime-dev.supabase-realtime  Created                                                                                             0.1s <br> ✔ Container supabase-pooler                 Created                                                                                             0.0s <br> ✔ Container supabase-rest                   Created                                                                                             0.0s <br> ✔ Container supabase-storage                Created                                                                                             0.0s <br>dependency failed to start: container supabase-db is unhealthy<br>Traceback (most recent call last):<br>  File &quot;/Users/kumarraj/personal/n8n/local-ai-packaged/start_<a href="http://services.py/">services.py</a>&quot;, line 95, in &lt;module&gt;<br>    main()<br>  File &quot;/Users/kumarraj/personal/n8n/local-ai-packaged/start_<a href="http://services.py/">services.py</a>&quot;, line 85, in main<br>    start_supabase()<br>  File &quot;/Users/kumarraj/personal/n8n/local-ai-packaged/start_<a href="http://services.py/">services.py</a>&quot;, line 61, in start_supabase<br>    run_command([<br>  File &quot;/Users/kumarraj/personal/n8n/local-ai-packaged/start_<a href="http://services.py/">services.py</a>&quot;, line 19, in run_command<br>    subprocess.run(cmd, cwd=cwd, check=True)<br>  File &quot;/Users/kumarraj/anaconda3/lib/python3.10/<a href="http://subprocess.py/">subprocess.py</a>&quot;, line 526, in run<br>    raise CalledProcessError(retcode, process.args,<br>subprocess.CalledProcessError: Command &#39;[&#39;docker&#39;, &#39;compose&#39;, &#39;-p&#39;, &#39;localai&#39;, &#39;-f&#39;, &#39;supabase/docker/docker-compose.yml&#39;, &#39;up&#39;, &#39;-d&#39;]&#39; returned non-zero exit status 1.
Stuck on the same step on windows as well, supabase-db step is in waiting stage forever.<br><br>Log says,<br><br>initdb: error: could not change permissions of directory &quot;/var/lib/postgresql/data&quot;: Operation not permitted<br>chmod: changing permissions of &#39;/var/lib/postgresql/data&#39;: Operation not permitted<br>The files belonging to this database system will be owned by user &quot;postgres&quot;.<br>This user must also own the server process.<br><br>The database cluster will be initialized with locale &quot;en_US.UTF-8&quot;.<br>The default database encoding has accordingly been set to &quot;UTF8&quot;.<br>The default text search configuration will be set to &quot;english&quot;.<br><br>Data page checksums are disabled.<br><br>any suggestions ??
Nobody has combined all of these open source things together into one downloadable file so users can just open and install to use easily yet?
Not yet! This is the closest thing to that from what I&#39;ve seen.
@@ColeMedinwhat is preventing someone from doing it if there are so many open source projects out there?
Cole, your mention at <a href="https://www.youtube.com/watch?v=pOsO40HSbOo&amp;t=1481">24:41</a> of needing to flip a few options on the n8n node illustrates how graphical low code tools are sometimes actually harder to learn because you can&#39;t leverage LLM to help you figure it out. Freshly Learned Tip: cut and paste the JSON of your n8n workflow as context for your query and ask away. Had good luck while trying out LFM-40B model today to reco settings, and reco what nodes are needed if you want to make certain changes to your workflow.
Yeah very true! Thanks for the tip too. I&#39;ve tried that before and gotten some pretty good results myself!
Why not podman instead of docker? ... Has podman desktop similar to docker but I think license is better no?
Podman is very similar to docker, I am using it.
@logeshmurugesan702  <br>I think for supabase at least  it would make more sense (as I understand  a POD can have all the complexity in one pod)
As the other reply mentioned you can use them pretty interchangeably. I mostly just use Docker because it is more widely recognized, but Podman does have better licensing for sure!
Local is so powerful and I truly think this is the future of AI serving businesses, I&#39;m amazed how you manage to build and deliver these gems, kudos !
I totally agree. Thanks David!
Hi! The file in github called &quot;Local_RAG_AI_Agent_n8n_Workflow.json&quot; seems to be updated yesterday but there are no local folder or Supabase in it.
Can you help me build an ai agent that can communicate with social media to advertise my products
very useful, as always!!
Man, you made my career.
Your vids and work are awesome.  Only way to improve...start using uv for your projects to make it even easier for everyone. :)
@ColeMedin can we run all services in Coolify ?
on my ned the supabase-pooler just restarts over and over again.
my read/write <a href="https://www.youtube.com/watch?v=pOsO40HSbOo&amp;t=1470">24:30</a> always outputs nothing, so nothing gets pushed to the database
See the README troubleshooting section - I call out what to do in this case there!
Can you run off of AMD rx on Windows?
I don&#39;t have an AMD GPU myself but the n8n local AI starter kit that I based this package on did include instructions for running with AMD which I have in my README. So not tested by me but I believe so!
Thanks for another great tutorial, and thank you for your hard work on putting this together for us newbies to AI.  Also, the docker command to remove orphaned containers is &quot;docker compose -f docker-compose.yml down --remove-orphans&quot;.
You are welcome Shawn! I actually think the warning about orphans is a &quot;false positive&quot;. It&#39;s warning me about the Supabase containers I just created so I don&#39;t think I actually want to remove them...
Good work again
Why Supabase instead of Qdrant? Also, can you do SFTP folder instead of local folder and use more complex files instead of just simple world file with few lines.
Good question! Supabase is both a SQL database and vector DB with the PGVector extension, so I love using it since I can use it as a single platform for both my agent conversation history and state management, and for RAG. I also will sometimes create RAG agents that can explore the knowledge in different ways with SQL queries, so it&#39;s nice to have the SQL table with all of that information AND a column for the vectors.<br><br>Haven&#39;t explored SFTP folders yet in n8n but I&#39;m sure this is possible! To be clear, the local file trigger will support any file type, it&#39;s just a matter of making sure the rest of the pipeline can actually extract the text from whatever file type.
Have you ever done a video that outlines the hardware recommended to run something like this?  It would be interesting to know what the Min/Low Cost setup // Sweet Spot setup and Dream setup would look like to give targets and set expectations.<br><br>Also, I se you do this in Windows, how much different would these requirements be for Linux or for Mac users?
I haven&#39;t and this is a video I definitely want to make soon!<br><br>The setup is practically the same for each operating system. There are some differences that are covered in the README!
@@ColeMedin I&#39;m interested in getting into making some videos on local LLMs and data privacy.  I have a fairly large home lab (10 racks, 312 servers) and It would be interesting to share some of the things I have learned so far.
Wow that is really impressive! I&#39;d really love to hear more about what you&#39;ve learned so far, feel free to email me at cole@<a href="http://dynamous.ai/">dynamous.ai</a>
So can you put this agent on chain too?
You mean on the blockchain? That is something I haven&#39;t experimented with yet, but that would be super cool.
Hi Cole congrats on getting it to work, what embeddings model did you use that has the same size as openai embedding
Thank you! I used nomic-embed-text from Ollama in this video. It&#39;s not actually the same size (it&#39;s dimensions is 768) but I updated the SQL queries for RAG to reflect that in this video.
Hey man really amazing video! Can you also make a video on deploying this on cloud with something like coolify
Yeah I actually do want to cover deploying this with Coolify! I did make a video a while ago deploying an older version of this stack to DigitalOcean:<br><br><a href="https://www.youtube.com/watch?v=259KgP3GbdE">https://www.youtube.com/watch?v=259KgP3GbdE</a>
Add some local voice recognition/generation modules pls (wisper +tts)
YES! Great suggestion :)
I hate and love you in the same time, i have been trying to do the same thing for 2 weeks i had sleepless night espically since i didnt want to use all the features of supabase with AI packaged kit i only wanted postgress db , studio, auth, rest and meta but the number of errors and to have them on the same network drove ne crazy in the end i went with smillar approach two networks and had everything thing running, i finished two days ago. Nkw you provide a complete setup easy to do 😂. Can we have deep session of how to setup and use the database with vector db as well the authentication full example.
Shoot I&#39;m sorry this didn&#39;t come sooner for you then! If it helps, often struggling endlessly through something like this actually teaches you the most. So you&#39;re probably much more of a Docker/Supabase/self hosting expert than most people now!<br><br>I appreciate the suggestion as well - I definitely want to do this!
@@ColeMedin one more thing i noticed in the compose yml file for open web ui and studio they are pointing to the same port:3000. also you may need to inclde th passward change for supabase_admin , supabase_auth_admin, postgress the ALTER comand. moreover i still have the pooler issue eventhough i folowed github and changed it to LF.<br>kong will not accept the user name and passward tried multiple times.
Interesting, I&#39;ll have to take a look at these things. Thanks for pointing them out!<br><br>Might have to entirely restart the stack for the pooler issue. Not sure what else it could be though if it really is changed to LF.
We are doing the same project. But Im doing it in kubernetes. An open infra of sorts for small and medium orgs. Wanna colab?
Sounds awesome! Is yours open source?
that would be an orchestration layer on top of what he&#39;s achieved here, and not a replacement, since Kubernetes uses Docker containers, and the softwares used have their default distribution in Docker. That would be a scaleout deployment setup, looking  forward to see what you come up with.
Digging the mustache sir
It&#39;s a first for me - I appreciate it man!
W🔥W
So effectively you could just install coolify to manage all the docker containers?
Yeah you can deploy entire Docker Compose stacks to Coolify pretty easily!<br><br><a href="https://coolify.io/docs/knowledge-base/docker/compose">https://coolify.io/docs/knowledge-base/docker/compose</a>
As someone who has been using (and shafted by) AWS since 2009, you can&#39;t really compare Supabase with AWS but, from a DB perspective: I know where my spend is with Supabase (in cloud) and not going to get unexpected bills at the end of the month. Supabase is a very important product in my world.
Yeah I&#39;m with you 100%!
thank you, keep it up, youll get some monetary support soon :)
Thank you! :D
I had a trouble updating n8n, ended up reinstalling the thing and got stuck with &quot;credentials couldn&#39;t be decrypted&quot;. This might just save me!
This is great, been thinking about how to integrate AI agents into some of my local ai application. Very informative!
Dang, your vids really are the absolute best. You have a real gift for explaining things super clearly.
I really appreciate that! Thank you :D
Nice video.  Realize you are using a Windows system and already ran Supabase, but on a Mac the fresh install errors out starting Supabase services. Tried starting the Supabase service first, but that also fails.  If anyone has success running the stack on MacOs, please let us know what steps you took. Thanks
Thanks! Wish I had a Mac to test this out on myself, so not sure what the issue could be. What is the error message you get?
@@ColeMedin Cole, first a huge thank you for putting in the thought and investing so much time to share your knowledge. You&#39;re impacting a lot of folks!!!<br><br>I also can&#39;t get Supabase running on Mac. The docker containers are up &amp; running but the connection to n8n fails. Specifically, the n8n doesn&#39;t seem to recognize the credentials for Supabase API:<br>- Host: http://host.docker.internal:8000/<br>- Service Role Secret: [from the .env file - JWT generated from the Supabase website]<br><br>The error received from n8n is: &quot;Service Unavailable&quot;.  I&#39;ve tried changing the host to http://kong:8000 and http://db:8000. Same result.<br><br>Sorry to ask a debugging question here.  <br><br>Any thoughts??
Could you check Docker and see if there are any containers that are offline that shouldn&#39;t be? Or any that are restarting constantly? Check the troubleshooting section of the README too, I have a couple common things there.
Actually, I went through your troubleshooting suggestions before my initial request for help. There isn’t any issue with Dicker containers.  There just needs to be different initial setup for Supabase.  If I were to make suggestions, please recommend Mac users follow Supabase documentation. I don’t have a recommendation on how to update your package since I split it into Supabase install first, then your package.
@@ColeMedin thanks very much for your responses and YouTube videos. Since Windows and Mac are pretty dissimilar, perhaps you could consider picking up a M3 or M4 Max with decent RAM to test your installations. In any case, I know how hard it is to support Windows/Mac/Linux. Likewise, once NVidia releases their Project Digits, I expect I’ll have yet another source of pain when running full stacks locally.  Thanks again
Been building my own ai agent framework and your videos have helped tremendously for getting the foundation paved, thank you!
That&#39;s awesome - props to you for building an agent framework from scratch. Not an easy task! You are very welcome!
So if you had Qdrant for vector and Postgres on the stack why would you need Supabase?
Good question! Supabase is really nice because it comes with other features like authentication, object store, realtime, and edge functions so you get a lot more than if you just use &quot;vanilla&quot; Postgres along with Qdrant.
@@ColeMedin it&#39;s still not a full version of supabase though right? I tried this last week and it deliberately closes off a lot of functions and features to you because you&#39;re self hosting, like you can&#39;t get to the projects page to set up different projects and keys etc and some of the security features are just not there. I spent hours going through this only to find that out
It&#39;s similar to if you self host Postgres where it&#39;s really only a single project, that is true. But you can simply self-host another Supabase stack to essentially create another project. What security features were missing for you?
Thanks for sharing.. instead you can use encore.ts full backend framework with GUI, supporting db &amp; api.  But much lightweight &amp; faster than supabase.
You bet! Encore.ts looks promising... I haven&#39;t actually checked it out until now!
Cole, at <a href="https://www.youtube.com/watch?v=pOsO40HSbOo&amp;t=1321">22:01</a> when talking about Supabase credentials, I think you mean to say the name of the Service not the name of the Container. The container in your compose file looks like &quot;supabase-db&quot;<br>Thanks for doing this. There was another video on self hosting Supabase that was so complicated, that I didn&#39;t even try it. This one seems better organized to deal with the stack of separate containers.
Yes that is correct! I realized that after recording that segment unfortunately. Pretty obvious rewatching after recording since the &quot;container_name&quot; line is literally right below the service name I&#39;m highlighting.<br><br>You are welcome Chris! Glad this walkthrough seems more straightforward to you.
Everyone should also move from Docker to Podman.
Awasome as every video you make. can i suggest Crawl4AI and openweb Pipelines container to complete the kit
and Kubernetes ?
Cole.. this is GOLD! great job as always bro! My feedback as requested for additional features would be to help get the local to pass through https using a domain with cloudflare tunneling so that i can access my local setup remotley through a secure browser. That would be fire for me and i have been running into trouble doing it myself.. mostly since n8n needs https webhooks when trying to work with external app triggers like telegram and whatsapp. But overall your content is the best i&#39;ve seen and always learn so much! Thank you!
Thanks man, that means a lot! Great suggestion too, I agree getting something like a reverse proxy set up in the stack is super important. Lot of options I am considering for this but I do want to do this pretty soon!
It seems everyone, including me, loves your video and this locally AI Agents package.
I appreciate it!!
Man I&#39;m so lost. Where is the file .env.example?
It&#39;s in the root of the GitHub repository! In the same place as the <a href="http://readme.md/">README.md</a> file.
What About Appwrite???
I think Appwrite is awesome, though I generally prefer Supabase since it more directly exposes SQL which I like. Certainly a case for the simplicity of Appwrite though, could be awesome to include this as an option in the local AI stack too!
@ColeMedin  thanks for your response and your clarification
You bet!
This is a very important video for me. Thank you Cole ❤
I&#39;m glad! You bet! :)
I&#39;ve been struggling to get this set up for over a week and going insane.  <br>This just might save the day Cole.  Cheers for putting in the effort!
Soooo 1000% true! I had it also very difficult
Dang that&#39;s a while, glad I could help you out!!
Nice local setup indeed! Question: what is the underlying machine (and Nvidia GPU) and Operating System that you use for your local development with the stack that you presented?
Thank you! Great question - I&#39;m running Windows 11 with a machine I built around two used 3090 GPUs I picked up last year.
I have low specification laptop should I build pc for AI?<br>if so then what confic i need and how much approx it will cost me !!
Depends on the size of models you want to run locally! If you want to run smaller LLMs (&lt;8b parameters) really any machine will do the trick. For larger LLMs like 32b parameters or more you&#39;ll start to need a better graphics card like a 3090, these kind of machines will be something around $1,500 - $2,000 starting.
@@ColeMedin thanks for your responce!!
You bet!
Like always high quality content 😊
I appreciate it! :D
Container `supabase-kong` is failing with &quot;init_by_lua error: /usr/local/share/lua/5.1/kong/init.lua:553: error parsing declarative config file /home/kong/kong.yml:<br> in &#39;basicauth_credentials&#39;:<br>   - in entry 1 of &#39;basicauth_credentials&#39;:<br>     in &#39;password&#39;: expected a string&quot; error
Very cool but, looks like Superbase is rather heavy for local use so I will rather stick with Qdrant.  🙂  Thanks much for the tip on what needs to be On for the Local File Trigger to work !!   I also added a Switch node after the Read/Write Files  to inspect the file extension and call the Extract from PDF vs Extract from Text , etc .  The tricky part was hooking that up with the Quadrant Vector Store and the Default Data Loader.  I am having fun with your video series.  Keep it up !
Yeah that is fair! One of the big reasons I left Qdrant in the stack.<br><br>You&#39;re welcome for the local file trigger tip - love your addition to the workflow too!
Love your videos, I am not a developer but run a software platform and like to experiment with things like this.. if only I had more time to play around with this stuff! Off topic, where did you get that desk with the shelves behind you??
Thanks Jeremy! I always wish I had more time too, always a million other things I wish I could experiment.<br><br>My background is actually AI generated! Hate to break it to ya haha
@@ColeMedin I thought about that but then said to myself no that looks too good and has to be real. Would love to hear the details on how to create something like this!
Haha it&#39;s mostly because I use a tool called Nvidia Broadcast - makes it look really real without any &quot;artifacting&quot; as I&#39;m moving my head around. The background itself I just generated with DALLE-3
sounds good!
Thanks!
Of course! Thank you for the support! :)
Graph RAG! Graph RAG!
fast-graphrag or nano-graphrag right?
Thanks for the video Cole! I’ve been wanting to host supabase locally 👏🏻
You bet!!
Using Macbook M3 my superbase container keeps restarting. kinda stuck ..
Which container? Is it the pooler one by chance? Take a look at the troubleshooting section in the README - I cover what to do if that is the case!
In your script to restart things, do you use docker compose down?   If you do, run the command docker compose down --help and look at the options.  There is a --remove-orphans that might help.
Yes I do! And actually I think the &quot;orphan detection&quot; is a false positive, if I remove orphans it would actually remove the Supabase containers I just created. I don&#39;t think those are old duplicates the warning message is referring to.
@@ColeMedin I have never created such a complex docker compose  file, and then joined it with another.  I know you can combine them, but it is complicated.  I am not surprised it is harder than it looks, but I just thought it was worth looking at.<br>Great video by the way.
Yeah I appreciate it! Thanks!
Larry Burkett&#39;s book on &quot;Giving and Tithing&quot; drew me closer to God and helped my spirituality. 2020 was a year I lived it. I cashed in my life savings and gave it all away. My total giving amounted to 40,000 dollars. Everyone thought I was delusional. Today, I receive 85,000 dollars every two months. I have a property in Calabasas, CA, and travel a lot. God has promoted me more than once and opened doors for me to live beyond my dreams. God kept to his promises to and for me
There&#39;s wonder-working power in following Kingdom principles on giving and tithing. Hallelujah!
But then, how do you get all that in that period? What is it you do please, mind sharing?
It is the digital market. That&#39;s been the secret to this wealth transfer. A lot of folks in the US and abroad are getting so much from it, God has been good to my household THANK YOU JESUS
Big thanks to Mr. OLIVER LEO ❤✨💯May God bless OLIVER LEO services, he has changed thousands of lives globally
😱Sounds familiar, I have heard he&#39;s name on several occasions.. and both his success stories in the wall Street journal!
@Cole Solid Intro Video
Thanks Daniel!
